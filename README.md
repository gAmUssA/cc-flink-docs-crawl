# ğŸš€ Confluent Cloud Flink Documentation Crawler

A Python-based web crawler that downloads Confluent Cloud Flink SQL documentation and generates an `llms.txt` file according to the [llmstxt.org](https://llmstxt.org) standard. This tool helps train Claude and other language models to understand Flink SQL dialect for Confluent Cloud.

## âœ¨ Features

- ğŸ•·ï¸ **Web Crawling**: Downloads documentation from configurable URL list
- ğŸ“ **Smart Content Extraction**: Parses HTML and extracts relevant text and code examples
- ğŸ¯ **llms.txt Generation**: Creates standardized format for LLM training
- ğŸ§¹ **Clean Output**: Removes navigation, headers, and non-essential content
- ğŸ”§ **Configurable**: Easy to add new documentation URLs
- ğŸ¨ **Colorful Interface**: Beautiful terminal output with emojis and colors
- ğŸš€ **Automated CI/CD**: GitHub Actions workflow for automatic crawling
- ğŸ“Š **Smart Dependencies**: Makefile with dependency tracking and sentinel files
- ğŸ“ **Organized Output**: Structured output directory with summaries and artifacts

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.7+
- GNU Make 4.0+ (for Makefile features)
  - On macOS: `brew install make` (available as `gmake`)
  - On Ubuntu/Debian: `sudo apt-get install make`

### Setup

```bash
# Clone the repository
git clone <repository-url>
cd cc-flink-docs-crawl

# Setup virtual environment and install dependencies
# Note: Use 'gmake' on macOS if you have GNU Make installed via Homebrew
gmake setup  # or 'make setup' on Linux

# Or manually:
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

## ğŸš€ Usage

### Quick Start

```bash
# Run the complete CI pipeline (recommended)
gmake ci-ready  # Setup, validate, crawl, and generate summary

# Or run individual steps
gmake setup     # Create virtual environment and install dependencies
gmake crawl     # Run the documentation crawler
gmake status    # Check build status
gmake summary   # Generate crawl summary

# Traditional workflow
gmake all       # Setup and crawl (without validation/summary)
```

### Manual Usage

```bash
# Activate virtual environment
source venv/bin/activate

# Run the crawler
python3 crawler.py
```

### Configuration

Add URLs to crawl in `links.txt`:
```
https://docs.confluent.io/cloud/current/flink/overview.html
https://docs.confluent.io/cloud/current/flink/get-started/overview.html
# Add more URLs here...
```

## ğŸ“ Project Structure

```
cc-flink-docs-crawl/
â”œâ”€â”€ crawler.py              # Main crawler script
â”œâ”€â”€ links.txt               # URLs to crawl
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Makefile               # Build automation (Davis-Hansson best practices)
â”œâ”€â”€ out/                   # Generated output directory
â”‚   â”œâ”€â”€ llms.txt           # Generated documentation
â”‚   â””â”€â”€ crawl-summary.md   # Crawl statistics and summary
â”œâ”€â”€ tmp/                   # Temporary build files
â”‚   â”œâ”€â”€ .deps-installed.sentinel
â”‚   â””â”€â”€ .tests-passed.sentinel
â”œâ”€â”€ venv/                  # Python virtual environment
â”œâ”€â”€ .github/workflows/     # GitHub Actions automation
â”‚   â”œâ”€â”€ auto-crawl.yml     # Automated crawling on links.txt changes
â”‚   â””â”€â”€ smoketest.yml      # Basic validation tests
â”œâ”€â”€ .gitignore             # Git ignore rules
â””â”€â”€ README.md              # This file
```

## ğŸ¯ Available Make Commands

### ğŸš€ Primary Commands
- `gmake help` - ğŸ“– Show available commands
- `gmake ci-ready` - ğŸš€ **Complete CI pipeline** (setupâ†’validateâ†’crawlâ†’summary)
- `gmake status` - ğŸ“Š Show build status
- `gmake clean` - ğŸ§¹ Remove generated files and virtual environment

### ğŸ”§ Individual Steps
- `gmake setup` - ğŸ”§ Create virtual environment and install dependencies
- `gmake validate` - ğŸ”¬ Validate crawler script syntax
- `gmake crawl` - ğŸ•·ï¸ Run the documentation crawler
- `gmake summary` - ğŸ“Š Generate crawl summary with statistics
- `gmake install` - ğŸ“¦ Install dependencies (requires setup first)

### ğŸ“ Development Commands
- `gmake test` - ğŸ§ª Run tests (placeholder)
- `gmake lint` - ğŸ” Run linting (placeholder)
- `gmake format` - ğŸ’… Format code (placeholder)
- `gmake all` - ğŸ¯ Setup and crawl documentation (legacy)

> **Note**: Use `gmake` on macOS with Homebrew-installed GNU Make, or `make` on Linux systems.

## ğŸš€ GitHub Actions Automation

The project includes automated crawling via GitHub Actions that triggers when `links.txt` is updated:

### ğŸ¯ Automatic Triggers
- **Push to main/develop**: When `links.txt`, `crawler.py`, or `requirements.txt` are modified
- **Pull requests**: Validates changes before merging
- **Manual trigger**: Via GitHub Actions UI with custom reason

### ğŸ“¦ Automated Artifacts
- **Downloadable artifacts**: `out/llms.txt`, `out/crawl-summary.md`, `links.txt` (30-day retention)
- **GitHub releases**: On main branch pushes, creates releases with crawl results
- **Job summaries**: Beautiful GitHub Actions summary with statistics

### ğŸ”„ Workflow Consistency
The GitHub Actions workflow uses the same Makefile targets as local development:
```yaml
# GitHub Actions runs the same command as local development
- name: ğŸš€ Run complete CI pipeline via Makefile
  run: make ci-ready
```

This ensures identical behavior between local development (`gmake ci-ready`) and CI/CD (`make ci-ready`).

### ğŸ¨ Visual Feedback
The workflow provides:
- âœ… Step-by-step progress with emojis
- ğŸ“Š Detailed statistics (lines processed, file size, crawl date)
- ğŸ¯ Clear success/failure indicators
- ğŸ“‹ Downloadable crawl summaries

## ğŸ“Š Output

The crawler generates `llms.txt` with:
- **Header**: Project title and description
- **Overview**: What the documentation covers
- **Core Documentation**: Links with brief descriptions
- **Full Content**: Complete extracted text with code examples
- **Code Examples**: SQL snippets formatted for easy parsing

## ğŸ”§ Configuration

### Adding New URLs
Edit `links.txt` to include additional documentation URLs:
```
https://docs.confluent.io/cloud/current/flink/new-page.html
```

### Customizing Output
Modify `crawler.py` to adjust:
- Content extraction selectors
- Text cleaning rules
- Output formatting
- Request delays and headers

## ğŸ§ª Development

### Running Tests
```bash
make test  # When tests are added
```

### Code Quality
```bash
make lint    # When linting is configured
make format  # When formatting is configured
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built for training Claude on Confluent Cloud Flink SQL
- Uses the [llmstxt.org](https://llmstxt.org) standard
- Inspired by the need for better LLM understanding of Flink SQL dialect

## ğŸ“ Support

If you encounter issues or have questions:
1. Check the existing issues
2. Create a new issue with detailed description
3. Include error logs and environment details

---

Happy crawling! ğŸ•·ï¸âœ¨